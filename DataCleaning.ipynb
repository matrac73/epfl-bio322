{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "cddd = pd.read_csv('cddd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Removing missing values \n",
    "We define a fonction to remove the missing values (NaN) in a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaN_remover(df): \n",
    "    \"\"\"\n",
    "    Remove the NaN values from a Dataframe. \n",
    "    \n",
    "    Parameters : \n",
    "    - df (pd.dataframe): Dataframe containing NaN.\n",
    "    \n",
    "    Returns : \n",
    "    - pd.dataframe : Original Dataframe without the lines containing NaN values \n",
    "    \"\"\"\n",
    "    df_without_NaN = df.copy()\n",
    "    df_without_NaN.dropna(inplace=True)\n",
    "    return df_without_NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a NaN checker function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaN_checker(df, pt=False) : \n",
    "    \"\"\"\n",
    "    Check for the presence of NaN in a Dataframe.\n",
    "    \n",
    "    Parameters: \n",
    "    - df (pd.dataframe): Dataframe potentially containing NaN.\n",
    "    \n",
    "    Returns : \n",
    "    - nan_check : boolean value indicating if there is NaN values in the Dataframe. \n",
    "    \"\"\"\n",
    "    nan_check = df.isna().any().any()\n",
    "    if pt == True :\n",
    "        print(\"Il y a des NaN dans le DataFrame :\", nan_check)\n",
    "    return nan_check\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we apply the NaN_checker function to the train.csv and cddd.csv datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a des NaN dans le DataFrame : False\n",
      "Il y a des NaN dans le DataFrame : True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "NaN_checker(train, True)\n",
    "NaN_checker(cddd, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is some NaN values in the cddd dataset. We could either remove them or replacing them with the column mean. For now we are just going to remove them with the NaN_remover function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cddd_without_NaN = NaN_remover(cddd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing constant predictors \n",
    "We define a function to remove the constant predictors from a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we need to define a function that separates numercical columns from the other in Dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_separator(df): \n",
    "    \"\"\"\n",
    "    Separate the numerical columns for the other in a Dataframe. \n",
    "    \n",
    "    Parameters: \n",
    "    - df (pd.dataframe) : Dataframe containing numerical and non numerical columns \n",
    "    \n",
    "    Return: \n",
    "    - colonnes_non_numeriques : non numerical columns from the Original Dataframe \n",
    "    - colonnes_numeriques : numerical colums form the Original Dataframe\n",
    "    \"\"\"\n",
    "    colonnes_numeriques = df.select_dtypes(include=['number'])\n",
    "    colonnes_non_numeriques = df.select_dtypes(exclude=['number'])\n",
    "    return  colonnes_non_numeriques, colonnes_numeriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constant_predictors_remover(df) : \n",
    "    \"\"\"\n",
    "    Remove constant columns from a Dataframe. \n",
    "    \n",
    "    Parameters : \n",
    "    - df (pd.dataframe) : Dataframe containing constant columns.\n",
    "    \n",
    "    Returns : \n",
    "    - pd.dtaframe : Original Dataframe without constant columns.\n",
    "    \"\"\"\n",
    "    non_numerical_columns, numerical_columns = numerical_separator(df) #splitting the non numerical and numerical columns in data frame\n",
    "    std_per_column = np.std(numerical_columns, axis=0) #calculating std for each numerical column \n",
    "    non_constant_columns = std_per_column[std_per_column != 0].index #selectioning non constant columns\n",
    "    df_clean_const_numerical = df.loc[:, non_constant_columns]\n",
    "    df_clean_const = pd.concat([non_numerical_columns, df_clean_const_numerical], axis=1)\n",
    "    return df_clean_const\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we apply the function to remove to constant columns to train.csv and cddd.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500, 1029)\n",
      "(3500, 1029)\n",
      "(1472, 513)\n",
      "(1472, 513)\n"
     ]
    }
   ],
   "source": [
    "train_clean_const = constant_predictors_remover(train)\n",
    "cddd_clean_const = constant_predictors_remover(cddd_without_NaN)\n",
    "\n",
    "print(train_clean_const.shape)\n",
    "print(train.shape) #same shapes => there was no constant column in the train Dataframe\n",
    "\n",
    "print(cddd_clean_const.shape)\n",
    "print(cddd_without_NaN.shape) #same shapes => there was no constant column in the cddd Datafrmae \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing correlated predictors\n",
    "We define a function to remove the perfectly correlated predictors from a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_remover(df) : \n",
    "    \"\"\"\n",
    "    Remove the correlated columns in a Dataframe. \n",
    "    \n",
    "    Parameters : \n",
    "    - df (pd.dataframe) : Dataframe with some perfectly correlated columns. \n",
    "    \n",
    "    Retruns : \n",
    "    - pd.dataframe : Original Dataframe with only non correlated columns (one of each group of prefectly correlated columns remains).\n",
    "    \"\"\"\n",
    "    non_numerical_columns, numerical_columns = numerical_separator(df)\n",
    "    correlation = np.array(numerical_columns.corr().values)\n",
    "    correlation = np.triu(correlation, k=0)\n",
    "    np.fill_diagonal(correlation,0)\n",
    "    df_clean_corr_numerical = numerical_columns.drop(numerical_columns.columns[np.where(correlation==1)[1]], axis=1)\n",
    "    df_clean_corr = pd.concat([non_numerical_columns, df_clean_corr_numerical], axis=1)\n",
    "    return df_clean_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we apply the function to the train.csv and cddd.csv datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500, 1029)\n",
      "(3500, 1029)\n",
      "(1472, 513)\n",
      "(1472, 513)\n"
     ]
    }
   ],
   "source": [
    "train_clean_corr = correlation_remover(train)\n",
    "cddd_clean_corr = correlation_remover(cddd_without_NaN)\n",
    "\n",
    "print(train.shape)\n",
    "print(train_clean_corr.shape) #same shapes => no perfectly correlated predictors in the train Dataframe\n",
    "\n",
    "print(cddd_without_NaN.shape)\n",
    "print(cddd_clean_corr.shape) #same shapes => no perfectly correlated predictors in the cddd Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strandardization \n",
    "We define a function to standardize our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def standardizer(df, target='RT'):\n",
    "    \"\"\"\n",
    "    Standardize numerical features in a DataFrame, including the target feature if present.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame to standardize.\n",
    "    - target (str): Name of the target feature (default is 'RT').\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Original DataFrame with standardized numerical features.\n",
    "    \"\"\"\n",
    "    non_numerical_columns, numerical_columns = numerical_separator(df)\n",
    "\n",
    "    # Extract the target feature, if present\n",
    "    if target in numerical_columns.columns:\n",
    "        target_feature = numerical_columns[target]\n",
    "        numerical_columns = numerical_columns.drop(columns=[target])\n",
    "\n",
    "        # Standardize numerical features\n",
    "        scaler = StandardScaler()\n",
    "        scaled_numerical_data = pd.DataFrame(scaler.fit_transform(numerical_columns),\n",
    "                                             columns=numerical_columns.columns)\n",
    "\n",
    "        # Concatenate non-numerical columns, target feature, and scaled numerical data\n",
    "        non_numerical_columns.reset_index(drop=True, inplace=True)\n",
    "        scaled_numerical_data.reset_index(drop=True, inplace=True)\n",
    "        df_scaled = pd.concat([non_numerical_columns, target_feature, scaled_numerical_data], axis=1)\n",
    "\n",
    "    else:\n",
    "        # Standardize numerical features (excluding target feature)\n",
    "        scaler = StandardScaler()\n",
    "        scaled_numerical_data = pd.DataFrame(scaler.fit_transform(numerical_columns),\n",
    "                                             columns=numerical_columns.columns)\n",
    "\n",
    "        # Concatenate non-numerical columns and scaled numerical data\n",
    "        non_numerical_columns.reset_index(drop=True, inplace=True)\n",
    "        scaled_numerical_data.reset_index(drop=True, inplace=True)\n",
    "        df_scaled = pd.concat([non_numerical_columns, scaled_numerical_data], axis=1)\n",
    "\n",
    "    return df_scaled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we apply the function to train.csv and cddd.csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled = standardizer(train)\n",
    "cddd_scaled = standardizer(cddd_without_NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data saving\n",
    "We save the obtained datasets in the repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "output_path = os.path.join(current_directory, \"train_scaled.csv\")\n",
    "train_scaled.to_csv(output_path, index=False)\n",
    "output_path = os.path.join(current_directory, \"cddd_scaled.csv\")\n",
    "cddd_scaled.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLCourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
